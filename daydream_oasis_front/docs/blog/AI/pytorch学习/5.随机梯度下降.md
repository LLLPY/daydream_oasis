
<BlogInfo title="5.随机梯度下降" author="白日梦想猿" pv=0 read_times=0 pre_cost_time=1分11秒 category="人工智能" tag_list="['人工智能']" create_time="2021.07.15 16:30:24" update_time="2021.07.31 18:04:19" />

```python
import numpy as np
import matplotlib.pyplot as plt

plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正确显示中文

'''
与梯度下降算法相比,为了跳出"鞍点",使用的是样本的损失值对w进行求导,而不再使用mse

'''

# 训练集
x_list = [i for i in np.arange(1.0, 4.0, 1.0)]
y_list = [i for i in np.arange(2.0, 8.0, 2.0)]


# 计数预测值的函数
def forward(x):
    return x * w


# 计算损失值的函数
def loss(x, y):
    pred_y = forward(x)  # 与之前的总损失值相比 现在用的就是当前这个样本对应的损失值
    return (pred_y - y) ** 2


# 计算梯度的函数
def gradient(x, y):
    return 2 * x * (forward(x) - y)


if __name__ == '__main__':

    # w的初始值设为1.0 学习率的初始值为0.01
    w = 1.0
    a = 0.01

    print(f'Predicted (before training) f(4)={forward(4)}')

    loss_list = []
    epoch_list = []  # 训练的轮速
    w_list = []
    N = 1
    for epoch in range(0, 100):
        for x, y in zip(x_list, y_list):
            epoch_list.append(N)
            loss_ = loss(x, y)
            loss_list.append(loss_)
            gradient_val = gradient(x, y)
            w_list.append(w)
            w -= a * gradient_val
            print(f'Epoch:{N} w={w} loss={loss_} f(4)={forward(4)}')
            N += 1
    print(f'Predicted (after training) f(4)={forward(4)}')

    plt.subplot(2, 1, 1)
    plt.plot(epoch_list, loss_list)
    plt.title('损失值(loss)-轮数(epoch)')
    plt.xlabel('epoch')
    plt.ylabel('loss')
    plt.subplot(2, 1, 2)
    plt.title('损失值(loss)-w')
    plt.plot(w_list, loss_list)
    plt.xlabel('w')
    plt.ylabel('loss')
    plt.show()

```
