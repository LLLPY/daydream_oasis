
<BlogInfo id="237" title="40.爬取" author="白日梦想猿" pv=0 read_times=0 pre_cost_time=0分49秒 category="爬虫学习" tag_list="['爬虫学习']" create_time="2020.06.14 08:28:19" update_time="2020.06.14 09:39:32" />

```python
#爬取所有页面的所有房源url信息
from lxml import etree
from selenium import webdriver
from time import sleep
from random import choice

start_url = 'https://jingmen.58.com/chuzu/?PGTID=0d3090a7-008f-867e-de29-b363e6c67ee3&ClickID=8'
f = open('house_urls.text','a',encoding='utf-8')

# chromeOptions = webdriver.ChromeOptions() #设置代理
# chromeOptions.add_argument('')
# chrome_options=chromeOptions
chrome = webdriver.Chrome()
chrome.get(start_url)

k = 1
while True:
    sleep(choice([1.5,2,2.3,3.4,4]))
    contents = chrome.page_source
    e = etree.HTML(contents)
    house_urls = e.xpath('//h2/a/@href')
    for i in range(len(house_urls)-1):
        f.write(house_urls[i])
        f.write('\n')
    chrome.find_element_by_xpath('//a[@class="next"]/span').click()
    sleep(choice([1.5, 2,3,3.4,4]))
    next_page = etree.HTML(chrome.page_source).xpath('//a[@class="next"]/span/text()')
    if str(next_page).find('下一页') == -1:
        break
    print('第{}爬取完成!'.format(k))
    k += 1

f.close()
```
