
<BlogInfo id="1116" title="38.TaylorSwift" author="白日梦想猿" pv=0 read_times=0 pre_cost_time="2分0秒" category="爬虫学习" tag_list="['爬虫学习']" create_time="2020.06.14 08:07:57" update_time="2020.09.08 14:09:02" />

```python
import queue
import random
from time import sleep
from lxml import etree
import requests
from selenium import webdriver
import threading
from fake_useragent import UserAgent

urls_queue = queue.Queue()


# 获取图片的url，并写入文件中
def get_index_urls():
    base_index_urls = 'https://www.duitang.com/album/?id=61281999#!albumpics-p{}'
    index_urls = [base_index_urls.format(i) for i in range(1, 9)]
    for url in index_urls:
        options = webdriver.ChromeOptions()
        options.add_argument('--headless')
        chrome = webdriver.Chrome(chrome_options=options)
        chrome.get(url)
        js = 'document.documentElement.scrollTop=1000000000'  # 将页面拉到底部
        chrome.execute_script(js)
        sleep(random.randint(2, 4))
        content = chrome.page_source
        e = etree.HTML(content)
        img_urls = e.xpath('//img/@src')
        print('获取以下图片地址:\n')
        with open('img_urls.txt', 'a', encoding='utf8') as f:
            for img_url in img_urls:

                if img_url and len(img_url) < 90 and len(img_url) >= 85 and '.png' not in img_url:
                    f.write(img_url)
                    f.write('\n')
                    print(img_url)

        print('第{}页爬取完成!'.format(index_urls.index(url) + 1))
        chrome.quit()


# 读取图片的url文件，并保存到队列中
def get_imgs_queue():
    with open('img_urls.txt', 'r', encoding='utf8') as f:
        content = f.read()
        base_urls = content.split('\n')
        for i in base_urls:
            # if i and len(i) < 90 and len(i) >= 85 and '.png' not in i:
            urls_queue.put(i)


# 从队列中获取url并访问下载图片
def get_imgs():
    while not urls_queue.empty():
        url = urls_queue.get()
        # print(url)
        # 忽略警告
        requests.packages.urllib3.disable_warnings()
        response = requests.get(url, headers={'User-Agent': UserAgent().chrome}, verify=False)
        contents = response.content
        with open('Taylor-Swift/泰勒斯威夫特-{}.jpg'.format(urls_queue.qsize()), 'wb') as f:
            f.write(contents)

        print('还剩{}张图片待爬取...'.format(urls_queue.qsize()))


# 多线程
def thread_spider(num=10):
    for i in range(num):
        # 创建线程
        p1 = threading.Thread(target=get_imgs)

        # 启动线程
        p1.start()

        # 等待线程结束再结束主进程
        p1.join()


if __name__ == '__main__':
    # 将url保存到文件中
    get_index_urls()

    # 将url保存到队列中
    # get_imgs_queue()

    # 开启多线程
    # thread_spider()

    print('爬取完成!')

```
