
<BlogInfo title="24.爬取图文并茂的文章" author="白日梦想猿" pv=0 read_times=0 pre_cost_time=1分19秒 category="爬虫学习" tag_list="['爬虫学习']" create_time="2020.06.02 15:03:58" update_time="2020.06.02 16:33:54" />

```python
#http://5b0988e595225.cdn.sohucs.com/images/20190317/6ada36d1986d4c968733fd6a54fd14a1.jpeg
#http://5b0988e595225.cdn.sohucs.com/images/20190317/a4b9b8b6cc0548438aa4b73008722d10.jpeg
import requests
import re
from fake_useragent import UserAgent
imags_url_list = []
headers = {
    'User-agent':UserAgent().random
}
url = 'https://www.sohu.com/a/301872112_710684'

#获取图片的url，返回url列表
def get_imags_url(url):
    response = requests.get(url, headers=headers)
    contents = response.text
    pattern = r'<p class="ql-align-center"><img src="(.*)" max-width="600" /></p> '
    contents = re.findall(pattern, contents)
    for i in contents:
        imags_url_list.append(i)
    return imags_url_list

#保存图片
def save_imags(imags_url_list):
    k = 1
    for i in imags_url_list:
        response = requests.get(i,headers=headers)
        contents = response.content
        with open('爬取的数据\美丽京山数据\图片数据\第{}张图片.jpg'.format(k),'wb') as f:
            f.write(contents)
        k += 1

#获取文字内容
def get_contents(url):
    response = requests.get(url,headers=headers)
    contents = response.text
    '''
    <p class="ql-align-center">.*</p><p>(.*)</p>
    '''
    pattern = r'<p>(.*)</p>'
    contents = re.findall(pattern,contents)
    contents[-1] = ''
    contents[-2] = '相约京山，寻找你心中的后花园。'
    with open('爬取的数据\美丽京山数据\文字数据\正文.txt','w+',encoding='utf-8') as f:
        for i in contents:
            f.write(i)
            f.write('\n')


if __name__ == '__main__':
    print('开始爬取....')
    get_contents(url)
    imags_url_list = get_imags_url(url)
    save_imags(imags_url_list)
    print('爬取完成!')

```
