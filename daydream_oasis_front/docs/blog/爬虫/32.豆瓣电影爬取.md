
<BlogInfo id="1110" title="32.豆瓣电影爬取" author="白日梦想猿" pv=0 read_times=0 pre_cost_time="2分59秒" category="爬虫学习" tag_list="['爬虫学习']" create_time="2020.06.07 17:36:40" update_time="2022.02.20 11:59:02" />

```python
from fake_useragent import UserAgent
from lxml import etree
import requests
from queue import Queue
urls_queue = Queue()
info_url_queue = Queue()
info_html_queue = Queue()
movies_queue = Queue()
#获取主页面的url,将获取的主页url保存在队列中
def get_urls():
    base_url = 'https://movie.douban.com/j/new_search_subjects?sort=U&range=0,10&tags=&start={}'
    for i in range(0,5020,20):
        url = base_url.format(i)
        urls_queue.put(url)

#从主页面中获取每个电影的url,将获取的电影url保存在队列中
def get_info_url():
    headers = {
        'User-agent':UserAgent().random
    }
    #忽略警告
    reques  ts.packages.urllib3.disable_warnings()
    if urls_queue.empty() == False:
        try:
            response = requests.get(urls_queue.get(),headers=headers,verify=False)
            if response.status_code == 200:
                for i in response.json()['data']:
                    info_url_queue.put(i['url'])
        except:
            print('格式错误!')


#获取每个电影的html,将每个电影的html保存在队列中
def get_info_html():
    headers = {
        'User-agent':UserAgent().random
    }
    # 忽略警告
    requests.packages.urllib3.disable_warnings()
    if info_url_queue.empty() == False:
        try:
            response = requests.get(info_url_queue.get(),headers=headers,verify=False)
            if response.status_code == 200 :
                info_html_queue.put(response.text)
        except:
            print('格式错误!')

#解析每个电影的源代码,获取相关信息
def parse_info_html():
    html = info_html_queue.get()
    if html != None:
        e = etree.HTML(html)
        name = e.xpath('//h1/span/text()') #名称
        #print('name:',name)
        derector = e.xpath('//span/a[@rel="v:directedBy"]/text()') #导演
        #print('derector:',derector)
        types = e.xpath('//span[@property="v:genre"]/text()') #类型
        #print('types:',types)
        country = str(e.xpath('//*[@id="info"]/text()')).replace('\n','').replace('        ','')  # 国家
        #print('country:', country)
        #language = e.xpath() #语言
        first_show_time1 = e.xpath('//*[@id="info"]/span[12]/text()') # 电影     上映时间 //*[@id="info"]/span[12]  //*[@id="info"]/span[10]
        first_show_time11 = len(str(first_show_time1).split('-'))
        first_show_time2 = e.xpath('//*[@id="info"]/span[10]/text()') #电视剧 2020-03-12(韩国)
        first_show_time22 = len(str(first_show_time2).split('-'))
        if first_show_time11 >= first_show_time22:
            first_show_time = first_show_time1
        else:
            first_show_time = first_show_time2
        #print('first_show_time:',first_show_time)
        score = e.xpath('//*[@id="interest_sectl"]/div/div[2]/strong/text()') #豆瓣得分
        #print('score:',score)
        actors = e.xpath('//span/a[@rel="v:starring"]/text()') #演员
        #print('actors:',actors)
        movie_dict = {str(name):{'name':str(name),'derector':str(derector),'types':str(types),'country':str(country),'score':str(score),'first_show_time':str(first_show_time),'actors':str(actors)}}
        movies_queue.put(movie_dict)
        if len(str(movie_dict).strip()) > 0:
            f.write(str(movie_dict))
            print(movie_dict)
            f.write('\n')
        print('还剩{}页信息待爬取...'.format(urls_queue.qsize()))


def spider():
    while urls_queue.empty() == False or info_html_queue.empty() == False or info_url_queue.empty() == False or movies_queue.empty() == False:
        get_info_url()
        get_info_html()
        parse_info_html()
        f.write('\n')

if __name__ == '__main__':
    print('开始爬取...')
    get_urls()
    f = open('爬取的数据\豆瓣电影信息.txt','a+',encoding='utf-8')
    spider()

    f.close()
    print('爬取完成!!!')

```
