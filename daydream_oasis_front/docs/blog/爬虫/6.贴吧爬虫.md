
<BlogInfo id="1123" title="6.贴吧爬虫" author="白日梦想猿" pv=0 read_times=0 pre_cost_time="0分56秒" category="爬虫学习" tag_list="['爬虫学习']" create_time="2020.05.30 13:23:42" update_time="2020.05.30 14:01:15" />

```python
from urllib.request import Request,urlopen

#获取贴吧内容，返回html
def get_contents(start,end):

    url = 'https://tieba.baidu.com/f?kw=%E6%AD%A6%E6%B1%89%E7%BA%BA%E7%BB%87%E5%A4%A7%E5%AD%A6&ie=utf-8&pn='

    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.61 Safari/537.36'
    }
    list = []
    for pn in range(int(start),int(end)+1):
        k = pn
        pn = 50 * (pn-1)
        url = url + str(pn)
        request = Request(url, headers=headers)
        response = urlopen(request)
        print('正在爬取第%d页内容...'%(k))
        html = response.read().decode()
        print('第%d页内容爬取完成...' % (k))
        list.append(html)
    print('已完成所有内容的爬取!')
    return list


#将获取的内容下载下来
def save_html(html_lsit,start,end):
    for i in range(int(start),int(end)+1):
        f = open('爬取的数据/贴吧爬取/第%d页内容.txt'%i,'w',encoding='utf-8')
        f.write(html_list[i-1])
        f.close()

if __name__ == '__main__':
    start = input('请输入要爬取的起始页:')
    end = input('请输入要爬取的终止页:')
    html_list = get_contents(start,end)
    save_html(html_list,start,end)






```
