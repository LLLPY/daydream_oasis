
<BlogInfo id="1117" title="39.爬取面经" author="白日梦想猿" pv=0 read_times=0 pre_cost_time="0分44秒" category="爬虫学习" tag_list="['爬虫学习']" create_time="2020.06.14 08:07:57" update_time="2022.01.26 16:26:49" />

```python
import csv
from lxml import etree
from requests import get

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/95.0.4638.69 Safari/537.36 Edg/95.0.1020.44',

}

url='https://mp.weixin.qq.com/s/RJjjA7h936PQCdUvzdZ_CQ'
response=get(url,headers=headers)
con=response.text
e=etree.HTML(con)
title_list=e.xpath('//p/a/text()')
link_list=e.xpath('//p/a/@href')

with open('后端面经.csv','w',encoding='utf8',newline='') as f:
    header=['title','地址']
    writer=csv.DictWriter(f,fieldnames=header)
    writer.writeheader()
    a=''
    for title,link in zip(title_list,link_list):
        if '后端' in title:
            print(title,link)
            conDic={
                header[0]:title,
                header[1]:link
            }
            a+=f'<a href="{link}">{title}</a><br>'
            writer.writerow(conDic)
    print(a)
```
