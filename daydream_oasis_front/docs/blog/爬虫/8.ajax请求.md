
<BlogInfo id="204" title="8.ajax请求" author="白日梦想猿" pv=0 read_times=0 pre_cost_time=1分20秒 category="爬虫学习" tag_list="['爬虫学习']" create_time="2020.05.30 15:10:25" update_time="2020.05.31 14:06:07" />

```python
from urllib.request import Request,urlopen
from fake_useragent import UserAgent
import re
#爬取电影信息
#在电影排行榜中，滚动鼠标，会发现电影的信息会慢慢增加，而不是一次性加载所有的电影信息，这种加载请求属于ajax请求
headers = {
    'User-Agent':UserAgent().firefox
}
start = 0
#https://movie.douban.com/j/chart/top_list?type=11&interval_id=100%3A90&action=&start=640&limit=20
#https://movie.douban.com/j/chart/top_list?type=11&interval_id=100%3A90&action=&start=640&limit=2000
base_url1 = 'https://movie.douban.com/j/chart/top_list?type=11&interval_id=100%3A90&action=&start='
base_url1 = 'https://movie.douban.com/j/chart/top_list?type=11&interval_id=100%3A90&action=&start='
base_url2 = '&limit=200'
k = 1
f = open('爬取的数据/贴吧爬取/电影数据.txt','a',encoding='utf-8')
for i in range(100):
    start = i * 20
    url = base_url1 + str(start) + base_url2
    k += 1
    request = Request(url,headers=headers)

    response = urlopen(request)

    contents = response.read().decode()
    if contents == '[]':
        break
    print(contents)
pattern = '[.."types":-"is_watched":false}..]'
# contents = re.sub(r'types','类型',contents)
# contents = re.sub(r'regions','国家',contents)
# contents = re.sub(r'title','名称',contents)
# contents = re.sub(r'url','播放地址',contents)
# contents = re.sub(r'release_date','上映日期',contents)
# contents = re.sub(r'actor_count','演员数量',contents)
# contents = re.sub(r'vote_count','播放量',contents)
# contents = re.sub(r'score','豆瓣评分',contents)
# contents = re.sub(r'actors','演员列表',contents)
#pattern = r'"类型".*,".*'
#contents = re.search(pattern, contents)
#f.write(str(contents.group()))
#print(contents.group())
f.close()


print('一共%d部电影信息'%(k-1))

```
