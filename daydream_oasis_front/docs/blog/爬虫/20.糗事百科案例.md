
<BlogInfo title="20.糗事百科案例" author="白日梦想猿" pv=0 read_times=0 pre_cost_time=1分10秒 category="爬虫学习" tag_list="['爬虫学习']" create_time="2020.05.31 19:56:06" update_time="2020.05.31 21:19:52" />

```python
from requests import *
from fake_useragent import UserAgent
import re
headers = {
    'User-agent':UserAgent().chrome
}
#设置一个代理
proxies = {
'http':'http://183.162.167.65:4216',
    'https':'http://61.160.195.93:808'

}


base_url1 = 'http://qiushidabaike.com/index_'
index = '1'
base_url2 = '.html'
f = open('爬取的数据\糗事百科.txt','a',encoding='utf-8')
m = 1
for i in range(1,201):
    index = str(i)
    print('正在爬取第%d页的内容...'%i)
    url = base_url1+index+base_url2
    response = get(url,headers=headers)
    contents = response.text
    pattern = r'\s*<p>.*</p>\s*</dd>\s'
    contents = re.findall(pattern, contents)
    #print(contents)
    if contents == '[]':
        break

    f.write('第%d的内容:\n' % i)
    for k in contents:

        xx = k.replace('\r\n\t\t\t\t<p>','【'+str(m)+'】').replace('</p>\t\t\t</dd>\r','').replace('<br/>',',')
        #print(xx)
        f.write(xx)
        f.write('\n')
        m += 1
    f.write('---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n')

    print('第%d的内容爬取完成...'%i)

f.close()




'''
<dd class="content">
				<p>本人近视，把大葱。</p>			</dd>
#pattern = r'<dd class="content">\s<p>.*</p>'
#pattern = r'\t\t\t\t<p>.*</p>\t\t\t</dd>\r'

'''



```
