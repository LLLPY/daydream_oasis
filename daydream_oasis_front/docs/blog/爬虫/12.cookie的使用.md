---

next: false

---



<BlogInfo id="1088" title="12.cookie的使用" author="白日梦想猿" pv=0 read_times=0 pre_cost_time="1分3秒" category="爬虫学习" tag_list="['爬虫学习']" create_time="2020.05.31 14:00:38" update_time="2021.01.26 13:37:16" />

```python
from urllib.request import Request,ProxyHandler,build_opener,HTTPCookieProcessor
from fake_useragent import UserAgent
from urllib.parse import urlencode
#当碰到需要使用账号登录后才能爬取的网页时，可以使用到cookie

headers = {
    'User-Agent':UserAgent().chrome
}

#登录
login_url = 'https://login.live.com/ppsecure/post.srf?wa=wsignin1.0&rpsnv=13&ct=1590909035&rver=6.7.6631.0&wp=MBI_SSL&wreply=https%3a%2f%2fcn.bing.com%2fsecure%2fPassport.aspx%3frequrl%3dhttps%253a%252f%252fcn.bing.com%252f%253fwlexpsignin%253d1%2526wlexpsignin%253d1%26sig%3d1B770A7507E06AF21B1604AE06CE6B3C&lc=2052&id=264960&CSRFToken=a422bda1-a27d-4b2a-8b3d-33d1ea4afcd3&aadredir=1&contextid=83F054DFD4E7ECE1&bk=1590909035&uaid=83f6ff83e9a040dabbd734862af11204&pid=0'
#登录的用户名和密码
form_data = {
    'User':'13047180318',
    'password':'LVll#1304718'
}
f_data = urlencode(form_data)
request = Request(login_url,headers=headers,data=f_data.encode())
hander = HTTPCookieProcessor()
opener = build_opener(hander)
login_response = opener.open(request)
login_contents = login_response.read().decode()
# print(login_contents)

#爬取登录后的页面(需要用之前登录成功的cookie)
url = 'https://cn.bing.com/?wlexpsignin=1&wlexpsignin=1'
request = Request(url,headers=headers)
response = opener.open(request)
contents = response.read().decode()
print(contents)
```



<ActionBox />
